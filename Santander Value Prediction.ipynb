{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29012aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a228439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fd066",
   "metadata": {},
   "source": [
    "# Case de Estudos: Santander Value Prediction\n",
    "\n",
    "Ajude Santander a identificar o valor das transações para cada cliente potencial. Esse é um primeiro passo que o Santander precisa acertar para personalizar seus serviços em grande escala.\n",
    "De acordo com uma pesquisa da Epsilon, 80% dos clientes tendem a voltar a fazer negócios com a sua empresa se a mesma entregar um serviço personalizado.\n",
    "\n",
    "<br>\n",
    "## Link para os dados e o desafio: \n",
    "\n",
    "https://www.kaggle.com/c/santander-value-prediction-challenge/data\n",
    "\n",
    "O case podera ser quebrado nas 6 partes seguintes:\n",
    "\n",
    "    Identificar o problema\n",
    "        Qual o tipo de problema(classificação, regressão, clustering)?\n",
    "    Necessidades de aplicar transformaçoes?\n",
    "        Ex: imputing de valores null, encoding de colunas string, etc\n",
    "    Separar os sets de treinamento e teste\n",
    "    Baseline\n",
    "        Achar uma baseline, um primeiro modelo para ter uma referencia\n",
    "    Escolher a metrica\n",
    "    Melhorar o resultado\n",
    "        Feature engineering, otimizaçao do modelo, hiperparametros, etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4634885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação e manipulação dos dataframes\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "#Operações matemáticas\n",
    "import numpy as np\n",
    "\n",
    "#Separar o dataframe em treino e teste\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Métricas de avaliação do modelo\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#Regressores utilizados\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "#Criação de Data Matrix para o XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "#Normalização dos dados \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "#Ignorar os avisos do sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Verificar o tempo de run de cada modelo \n",
    "from time import time\n",
    "\n",
    "#Visualização gráfica dos dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_submission = pd.read_csv('sample_submission.csv')\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cbb289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ff85154c8</td>\n",
       "      <td>1065000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>ffb6b3f4f</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ffcf61eb6</td>\n",
       "      <td>2800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ffea67e98</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>ffeb15d25</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4459 rows × 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0     000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1     000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2     0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3     0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4     002a68644  14400000.0        0.0          0        0.0          0   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "4454  ff85154c8   1065000.0        0.0          0        0.0          0   \n",
       "4455  ffb6b3f4f     48000.0        0.0          0        0.0          0   \n",
       "4456  ffcf61eb6   2800000.0        0.0          0        0.0          0   \n",
       "4457  ffea67e98  10000000.0        0.0          0        0.0          0   \n",
       "4458  ffeb15d25  20000000.0        0.0          0        0.0          0   \n",
       "\n",
       "      2f0771a37  30347e683  d08d1fbe3  6ee66e115  ...  3ecc09859  9281abeea  \\\n",
       "0             0          0          0          0  ...        0.0        0.0   \n",
       "1             0          0          0          0  ...        0.0        0.0   \n",
       "2             0          0          0          0  ...        0.0        0.0   \n",
       "3             0          0          0          0  ...        0.0        0.0   \n",
       "4             0          0          0          0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "4454          0          0          0          0  ...        0.0        0.0   \n",
       "4455          0          0          0          0  ...        0.0        0.0   \n",
       "4456          0          0          0          0  ...        0.0        0.0   \n",
       "4457          0          0          0          0  ...        0.0        0.0   \n",
       "4458          0          0          0          0  ...        0.0        0.0   \n",
       "\n",
       "      8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n",
       "0           0.0          0          0          0          0          0   \n",
       "1           0.0          0          0          0          0          0   \n",
       "2           0.0          0          0          0          0          0   \n",
       "3           0.0          0          0          0          0          0   \n",
       "4           0.0          0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4454        0.0          0          0          0          0          0   \n",
       "4455    80000.0          0          0          0          0          0   \n",
       "4456        0.0          0          0          0          0          0   \n",
       "4457        0.0          0          0          0          0          0   \n",
       "4458        0.0          0          0          0          0          0   \n",
       "\n",
       "      7e293fbaf  9fc776466  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "...         ...        ...  \n",
       "4454          0          0  \n",
       "4455          0          0  \n",
       "4456          0          0  \n",
       "4457          0          0  \n",
       "4458          0          0  \n",
       "\n",
       "[4459 rows x 4993 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14e551",
   "metadata": {},
   "source": [
    "## Visualização gráfica do target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(range(df.shape[0]), np.sort(df['target'].values))\n",
    "plt.xlabel('Index', fontsize=16)\n",
    "plt.ylabel('Target', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64189d1",
   "metadata": {},
   "source": [
    "## Verificar por valores nulos no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_nulos(df):\n",
    "    i = 0\n",
    "    for coluna in df.columns:\n",
    "        if df[coluna].isnull().sum() > 0:\n",
    "            print(f'A coluna {coluna} possui {df[coluna].isnull().sum()} valores nulos.')\n",
    "        \n",
    "        if df[coluna].isnull().sum() == 0:\n",
    "            i += 1\n",
    "    \n",
    "    if i == df.shape[1]:\n",
    "        print('O dataframe não possui nenhum valor nulo')\n",
    "        \n",
    "verificar_nulos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = []\n",
    "\n",
    "print(f'Shape do dataframe antes: {df.shape}')\n",
    "\n",
    "for col in df.columns:\n",
    "    if col != 'ID' and col != 'target':\n",
    "        if df[col].std() == 0:\n",
    "            colunas.append(col)\n",
    "            \n",
    "df.drop(columns=colunas, inplace=True)\n",
    "\n",
    "print(f'Shape do dataframe depois: {df.shape}')\n",
    "\n",
    "print(f'As colunas {colunas} foram removidas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando o uso de memória do dataframe\n",
    "print(f'Memória usada: {df.memory_usage().sum()/(1024*1024):.2f} MBs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03dfe18",
   "metadata": {},
   "source": [
    "## Separando o dataset em treino, teste e validação (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop(['ID', 'target'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f'Shape X_Train: {X_train.shape}')\n",
    "print(f'Shape y_Train: {y_train.shape}')\n",
    "print(f'Shape X_Test: {X_test.shape}')\n",
    "print(f'Shape y_Test: {y_test.shape}')\n",
    "print(f'Shape X_Validation: {X_validation.shape}')\n",
    "print(f'Shape y_Validation: {y_validation.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73114fd0",
   "metadata": {},
   "source": [
    "## Testando os diferentes tipos de escalonamento com alguns modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c79a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "    KNeighborsRegressor()\n",
    "]\n",
    "\n",
    "for scaler in scalers:\n",
    "    scaler = scaler.fit(X_train, X_test)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(f'Atual método utilizado: {scaler.__class__.__name__}')\n",
    "    print(f'')\n",
    "    \n",
    "    for model in models:\n",
    "        regressor = model.fit(X_train, y_train)\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        print(f'O modelo {model.__class__.__name__} teve um MAE de {mean_absolute_error(y_test, y_pred)} e um r2 score de {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bfde2",
   "metadata": {},
   "source": [
    "## Testando os scalers com a divisão de apenas treino/teste de 80-20 no CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf875e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método utilizado: StandardScaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 8385726.8574788\ttest: 7652349.2934808\tbest: 7652349.2934808 (0)\ttotal: 1.61s\tremaining: 13m 23s\n"
     ]
    }
   ],
   "source": [
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "#Separando o conjunto de dados em treino e teste\n",
    "y = df['target']\n",
    "X = df.drop(['ID', 'target'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.50, random_state=42)\n",
    "\n",
    "#Testando cada scaler unicamente\n",
    "for scaler in scalers:\n",
    "    print(f'Método utilizado: {scaler.__class__.__name__}')\n",
    "    scaler = scaler.fit(X_train, X_test)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    regressor = CatBoostRegressor(iterations=500, learning_rate=0.01, depth=10, eval_metric='RMSE',\n",
    "                             random_seed=42, bagging_temperature=0.2, od_type='Iter', \n",
    "                             metric_period=50, od_wait=20)\n",
    "\n",
    "    regressor.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True, verbose=50)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
    "    print(f'R2:{r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3211f69",
   "metadata": {},
   "source": [
    "## Normalizando os dados com o Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler = StandardScaler().fit(X_train, X_test)\n",
    "X_train = standardscaler.transform(X_train)\n",
    "X_test = standardscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82e48ec",
   "metadata": {},
   "source": [
    "## Normalizando os dados com o MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1356909",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = MinMaxScaler().fit(X_train, X_test)\n",
    "X_train = minmaxscaler.transform(X_train)\n",
    "X_test = minmaxscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e23229",
   "metadata": {},
   "source": [
    "## Normalizando os dados com o Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82470c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustscaler = RobustScaler().fit(X_train, X_test)\n",
    "X_train = robustscaler.transform(X_train)\n",
    "X_test = robustscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d3271",
   "metadata": {},
   "source": [
    "## Testando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583f320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Criando a lista dos modelos que serão testados\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    RandomForestRegressor(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    SVR(),\n",
    "    GaussianProcessRegressor(),\n",
    "    XGBRegressor(),\n",
    "    CatBoostRegressor(),\n",
    "    LGBMRegressor()\n",
    "]\n",
    "\n",
    "#Criando as listas vazias das métricas do modelo\n",
    "MAE = []\n",
    "RMSE = []\n",
    "MSE = []\n",
    "r2 = []\n",
    "names = []\n",
    "parameters = []\n",
    "tempo = []\n",
    "\n",
    "#Testando modelo por modelo\n",
    "for model in models:\n",
    "    #Startando o cronometro para ver o tempo de cada modelo \n",
    "    tempo_inicial = time()\n",
    "    \n",
    "    #Chamando o regressor e fazendo o predict\n",
    "    regressor = model.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    \n",
    "    #Adicionando o valor da métrica de cada modelo para criar o dataframe depois\n",
    "    MAE.append(mean_absolute_error(y_test, y_pred))\n",
    "    RMSE.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    MSE.append(mean_squared_error(y_test, y_pred))\n",
    "    r2.append(r2_score(y_test, y_pred))\n",
    "               \n",
    "    #Para pegar o nome do modelo basta pegar o nome da clas\n",
    "    names.append(model.__class__.__name__)\n",
    "               \n",
    "    #Para pegar os parametros utilizados\n",
    "    parameters.append(model.get_params())\n",
    "               \n",
    "    #Parando o cronometro para ver o tempo e adicionando na lista \n",
    "    tempo_final = time() - tempo_inicial\n",
    "    tempo.append(tempo_final)\n",
    "               \n",
    "               \n",
    "#Criando o dataframe com as métricas de todos os modelos \n",
    "resultado = pd.DataFrame({'Nome': names,\n",
    "                         'Parametros': parameters,\n",
    "                         'MAE': MAE,\n",
    "                         'RMSE': RMSE,\n",
    "                         'MSE': MSE,\n",
    "                         'R2': r2,\n",
    "                         'Run Time': tempo})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7db4b",
   "metadata": {},
   "source": [
    "# Tuning dos hiperparametros "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbeb7c",
   "metadata": {},
   "source": [
    "### Utilizando o SelectKBest para verificar as features mais importantes para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melhorar o resultado do SelectKBest utilizando o RandomForest Regressor\n",
    "sel_kbest = SelectKBest(f_regression, k=45).fit(X_train, y_train)\n",
    "X_train_sel = sel_kbest.transform(X_train)\n",
    "X_test_sel = sel_kbest.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor(max_depth=6, random_state=0)\n",
    "regressor.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test_sel)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4597ebe",
   "metadata": {},
   "source": [
    "## Utilizando o GridSearchCV para encontrar os melhores parametros para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando o GridSearchCV para encontrar os melhores valores para os parametros\n",
    "parameters = {'max_depth':[2,6,10,20,30,40],\n",
    "              'n_estimators':[20,50,100,200,300,500],\n",
    "              'max_features':['sqrt', 'log2']}\n",
    "\n",
    "regressor = GridSearchCV(RandomForestRegressor(), parameters, n_jobs=-1, verbose=1)\n",
    "regressor.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test_sel)\n",
    "\n",
    "print('MAE do modelo utilizando gridsearchCV')\n",
    "print(mean_absolute_error(y_train, y_train_pred))\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(regressor.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd31ee",
   "metadata": {},
   "source": [
    "## Utilizando o GridSearch no XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'learning_rate': np.arange(0, 0.35, 0.05),\n",
    "    'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': np.arange(0, 0.5, 0.1),\n",
    "    'colsample_bytree': [0.3, 0.4, 0.5 , 0.7]\n",
    "}\n",
    "\n",
    "regressor = GridSearchCV(XGBRegressor(), parameters, n_jobs=-1, verbose=2)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(regressor.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37806ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_regressor(train_x, train_y, validation_x, validation_y, test_x):\n",
    "    parameters = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.001,\n",
    "        'max_depth': 10,\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'alpha': 0.001,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #Transformando os dados em uma Data Matrix do XGboost\n",
    "    training_data = xgb.DMatrix(train_x, train_y)\n",
    "    validation_data = xgb.DMatrix(validation_x, validation_y)\n",
    "    testing_data = xgb.DMatrix(test_x)\n",
    "    \n",
    "    watchlist = [(training_data, 'train'), (validation_data, 'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(parameters, training_data, 50, watchlist, maxizime=False,\n",
    "                         early_stopping_rounds=100, verbose_eval=100)\n",
    "    \n",
    "    \n",
    "    predict_test_xgb = np.expm1(model_xgb.predict(data_test, ntree_limit=model_xgb.best_ntree_limit))\n",
    "    \n",
    "    return predict_test_xgb, model_xgb\n",
    "\n",
    "\n",
    "predictions_test_y_xgb, model_xgb = xgb_regressor(X_train, y_train, X_validation, y_validation, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb465a",
   "metadata": {},
   "source": [
    "## Tuning do modelo CatBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = CatBoostRegressor(iterations=1000, learning_rate=0.01, depth=10, eval_metric='RMSE',\n",
    "                             random_seed=42, bagging_temperature=0.2, od_type='Iter', \n",
    "                             metric_period=50, od_wait=20)\n",
    "\n",
    "regressor.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True, verbose=50)\n",
    "y_pred = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ad33b",
   "metadata": {},
   "source": [
    "## Criando o dataframe para submissão do desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fad73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
